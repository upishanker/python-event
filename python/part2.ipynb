{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e4de94a",
   "metadata": {},
   "source": [
    "# Python Basics for Neuro/DataSci\n",
    "## Part 2: Advanced Concepts & Event-Related Potentials (ERP)\n",
    "\n",
    "Welcome to Part 2! In Part 1, you learned the fundamental Python concepts. Now we'll build on those skills with advanced techniques and apply them to real neuroscience data analysis.\n",
    "\n",
    "### What We'll Cover:\n",
    "1. **Advanced Data Handling**: Multi-dimensional arrays and trial-based data\n",
    "2. **Statistical Concepts**: Trial averaging, confidence intervals, and variability\n",
    "3. **Real EEG Analysis**: Event-Related Potentials from human brain recordings\n",
    "4. **Professional Methods**: Bootstrap statistics and hypothesis testing\n",
    "5. **Research Workflow**: Complete neuroscience data analysis pipeline\n",
    "\n",
    "### Prerequisites Met in Part 1:\n",
    "- Python syntax and data types\n",
    "- NumPy arrays, indexing, and basic operations\n",
    "- Matplotlib visualization\n",
    "- Functions and control flow\n",
    "- File loading basics\n",
    "\n",
    "Let's bridge from Part 1 concepts to advanced neuroscience analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f6bfe",
   "metadata": {},
   "source": [
    "# Bridging Part 1 to Advanced Analysis\n",
    "\n",
    "Great job completing Part 1! Before we dive into real brain data, let's build some advanced concepts that bridge your foundational skills to professional neuroscience analysis.\n",
    "\n",
    "## Why These Advanced Concepts Matter\n",
    "\n",
    "In Part 1, you worked mostly with simple arrays and individual signals. Real neuroscience data is more complex:\n",
    "- **Multiple trials** of the same experiment (to reduce noise)\n",
    "- **Multi-dimensional datasets** (trials × time points × channels)\n",
    "- **Statistical uncertainty** (how reliable are our measurements?)\n",
    "- **Hypothesis testing** (are differences between conditions real?)\n",
    "\n",
    "Let's build these concepts step by step, using the same tools you already know from Part 1!\n",
    "\n",
    "## 1. Working with Multi-Dimensional Data\n",
    "\n",
    "Many neuroscience datasets have multiple dimensions. Understanding how to handle these is crucial for analyzing real brain recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we learned in Part 1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a multi-trial dataset (like real neuroscience experiments!)\n",
    "np.random.seed(123)  # For reproducibility\n",
    "n_trials = 200 # 1000 trials\n",
    "n_timepoints = 500 # 500 samples\n",
    "time = np.linspace(0, 1, n_timepoints) # 500 time points (samples) from 0 to 1 second\n",
    "\n",
    "# Simulate multiple trials of a signal with noise\n",
    "# This mimics how real experiments work: same stimulus, different noise each trial\n",
    "trials_data = np.zeros((n_trials, n_timepoints))\n",
    "for trial in range(n_trials):\n",
    "    # Each trial has the same underlying signal plus different noise\n",
    "    signal = np.sin(2 * np.pi * 5 * time)  # 5 Hz signal (like a brain rhythm)\n",
    "    noise = np.random.normal(0, 0.5, n_timepoints)  # Random noise\n",
    "    trials_data[trial] = signal + noise\n",
    "\n",
    "print(f\"Data shape: {trials_data.shape}\")\n",
    "print(\"This means: {} trials × {} time points\".format(*trials_data.shape))\n",
    "print(\"\\nThis is exactly like real EEG data structure!\")\n",
    "\n",
    "# Complicated plot: it's just ploting trials 1-12, 13-999, and the last trial to not overcrowd the legend\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(n_trials):\n",
    "    if i < 9:\n",
    "        plt.plot(time, trials_data[i], alpha=0.3, label=f'Trial {i+1}')\n",
    "    elif i == 9:\n",
    "        plt.plot(time, trials_data[i], alpha=0.3, label='Trial 10')\n",
    "    elif i == 10:\n",
    "        plt.plot(time, trials_data[i], alpha=0.3, label='Trial 11')\n",
    "    elif i == 11:\n",
    "        plt.plot(time, trials_data[i], alpha=0.3, label='Trial 12')\n",
    "    elif i == 99:\n",
    "        plt.plot(time, trials_data[i], alpha=0.3, label='Trial 13-999')\n",
    "    elif i == n_trials - 1:\n",
    "        plt.plot(time, trials_data[i], alpha=0.3, label=f'Trial {n_trials}')\n",
    "    else:\n",
    "        plt.plot(time, trials_data[i], alpha=0.3)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Multiple Trials: Same Signal + Different Noise')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Simpler plot: all trials overlayed but only label first 10 trials to avoid overcrowding the legend\n",
    "plt.figure(figsize=(10,6))\n",
    "for i in range(n_trials):\n",
    "    plt.plot(time, trials_data[i], alpha=0.1, label= f'Trial {i+1}' if i < 10 else None)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('All Trials Overlayed')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "print(\"Notice: Each trial looks different due to noise,\")\n",
    "print(\"but they all contain the same underlying 5 Hz signal!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2886e",
   "metadata": {},
   "source": [
    "## 2a. The Power of Averaging: From Noise to Signal\n",
    "\n",
    "Here's the key insight that makes neuroscience possible: **averaging across trials reveals hidden signals**!\n",
    "\n",
    "This is the foundation of Event-Related Potentials (ERPs) and many other neuroscience techniques:\n",
    "- Individual trials are noisy (hard to see the signal)\n",
    "- Random noise cancels out when averaged\n",
    "- Consistent signals become clear\n",
    "- This is why we need many trials in experiments\n",
    "\n",
    "Let's see this magic in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average across trials (this is what an ERP is!)\n",
    "average_signal = np.mean(trials_data, axis=0)  # axis=0 means average across trials\n",
    "\n",
    "# Create a comparison plot: Individual trials vs Average\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Top subplot: Individual trials (noisy)\n",
    "plt.subplot(2, 1, 1)\n",
    "for i in range(n_trials):\n",
    "    plt.plot(time, trials_data[i], 'gray', alpha=0.3)\n",
    "plt.plot(time, trials_data[0], 'blue', alpha=0.7, linewidth=2,\n",
    "          label='One single trial out of 10')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Individual Trials (Noisy - hard to see the signal!)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Bottom subplot: Average (clean!)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time, average_signal, 'red', linewidth=3, \n",
    "         label='Average across all trials')\n",
    "plt.plot(time, np.sin(2 * np.pi * 5 * time), 'black', linestyle='--', \n",
    "         linewidth=2, label='True underlying signal')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Average Signal (Clean - the signal emerges!)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The Magic of Averaging!\")\n",
    "print(f\"Single trial amplitude variation: ±{np.std(trials_data[0]):.3f}\")\n",
    "print(f\"Average signal peak: {np.max(np.abs(average_signal)):.3f}\")\n",
    "print(f\"True signal peak: 1.000\")\n",
    "print(f\"Accuracy improvement: {((1.0 - abs(np.max(np.abs(average_signal)) - 1.0))/1.0)*100:.1f}%\")\n",
    "print(\"\\nThis is EXACTLY what we'll do with real brain signals!\")\n",
    "print(\"EEG trials are noisy → average them → reveal the ERP!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40adcdcf",
   "metadata": {},
   "source": [
    "## 2b. Statistical Thinking: Uncertainty and Confidence\n",
    "\n",
    "When we compute an average, we need to know: **How reliable is this measurement?**\n",
    "\n",
    "We can use **confidence intervals** to quantify uncertainty:\n",
    "- **Standard deviation**: How much do individual trials vary?\n",
    "- **Standard error**: How much might our average vary if we repeated the experiment?\n",
    "- **Confidence intervals**: The range where the true value likely lies\n",
    "\n",
    "This statistical thinking is crucial for interpreting brain data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b18a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistical measures (using NumPy functions from Part 1!)\n",
    "signal_std = np.std(trials_data, axis=0)  # Standard deviation across trials\n",
    "signal_sem = signal_std / np.sqrt(n_trials)  # Standard error of the mean\n",
    "\n",
    "# 95% confidence intervals (±2 standard errors)\n",
    "ci_upper = average_signal + 2 * signal_sem\n",
    "ci_lower = average_signal - 2 * signal_sem\n",
    "\n",
    "# Create a professional statistical plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time, average_signal, 'red', linewidth=3, label='Average signal')\n",
    "plt.fill_between(time, ci_lower, ci_upper, \n",
    "                 alpha=0.3, color='red', label='95% Confidence Interval')\n",
    "plt.plot(time, np.sin(2 * np.pi * 5 * time), 'black', linestyle='--', \n",
    "         linewidth=2, label='True signal', alpha=0.7)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Average Signal with Statistical Confidence')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"Statistical Summary:\")\n",
    "print(f\"Number of trials: {n_trials}\")\n",
    "print(f\"Average amplitude: {np.max(average_signal):.3f}\")\n",
    "print(f\"Standard error: {np.max(signal_sem):.3f}\")\n",
    "print(f\"Confidence interval width: {np.max(ci_upper - ci_lower):.3f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Confidence interval shows measurement reliability\")\n",
    "print(\"- Narrower intervals = more confident in our measurement\")\n",
    "print(\"- This helps us distinguish real signals from noise\")\n",
    "print(\"\\nNow we're ready for real brain data analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d65e9e",
   "metadata": {},
   "source": [
    "## 3. Making Connections to Real Brain Data Analysis\n",
    "\n",
    "Perfect! You now understand the advanced concepts needed for professional neuroscience analysis:\n",
    "- Multi-dimensional data handling\n",
    "- Trial averaging for noise reduction  \n",
    "- Statistical confidence intervals\n",
    "- Professional visualization techniques\n",
    "\n",
    "Now let's apply these **exact same concepts** to real human brain recordings!\n",
    "\n",
    "### The EEG Experiment\n",
    "\n",
    "**Scenario**: An undergraduate student listens to two types of audio tones while we record brain activity.\n",
    "\n",
    "**Data**: 1000 trials each of high-pitch and low-pitch tones, recorded at 500 Hz for 1 second per trial (sampling rate 500 Hz, i.e., 500 EEG electrode readings/samples per second),\n",
    "\n",
    "**Question**: Do the brain responses differ between the two tone types?\n",
    "\n",
    "**Method**: Use everything we just learned - the same code, just with real brain data!\n",
    "\n",
    "### Before We Compute ERPs\n",
    "So far we've:\n",
    "1. Seen how multiple noisy trials conceal an underlying signal.\n",
    "2. Watched averaging reveal that signal.\n",
    "3. Quantified uncertainty with confidence intervals.\n",
    "\n",
    "In the real EEG data we are about to:\n",
    "- Load trials from two experimental conditions.\n",
    "- Visualize a few single trials (to appreciate the noise level).\n",
    "- Align them in time to the stimulus.\n",
    "- Compute the ERP for each condition (just a mean across trials!).\n",
    "- Attach 95% confidence information to those ERPs.\n",
    "- Then compare the two conditions.\n",
    "\n",
    "> Key idea: An ERP is **nothing more** than the trial-wise average, interpreted in the context of timing and uncertainty.\n",
    "\n",
    "Next, we'll start by looking at a couple of individual real EEG trials, and then move directly into computing the ERPs in Section 4b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real brain data using the same libraries from Part 1!\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load the EEG data (just like loading any data file)\n",
    "data = loadmat('02_EEG-1.mat')\n",
    "EEGa = data['EEGa']             # EEG data from condition A (high pitch tone)\n",
    "EEGb = data['EEGb']             # EEG data from condition B (low pitch tone)\n",
    "t = data['t'][0]                # Time axis\n",
    "\n",
    "# Examine the data structure (using skills we just practiced!)\n",
    "ntrials, nsamples = EEGa.shape  # Multi-dimensional data - just like our simulation!\n",
    "print(f\"Real EEG data shape: {ntrials} trials × {nsamples} time points\")\n",
    "print(\"Same structure as our simulated data, but now it's real brain signals!\")\n",
    "\n",
    "print(f\"\\nExperiment details:\")\n",
    "print(f\"Trial duration: {t[-1]:.3f} seconds\")\n",
    "print(f\"Sampling rate: {1/(t[1]-t[0]):.0f} Hz\") \n",
    "print(f\"Stimulus occurs at: 0.25 seconds\")\n",
    "print(f\"Total trials: {ntrials} per condition\")\n",
    "\n",
    "# Compare data ranges between conditions\n",
    "print(f\"\\nData characteristics:\")\n",
    "print(f\"Condition A (high pitch) voltage range: {np.ptp(EEGa):.2f} µV\")\n",
    "print(f\"Condition B (low pitch) voltage range: {np.ptp(EEGb):.2f} µV\")\n",
    "\n",
    "print(\"\\nThis is real human brain activity!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot single trial from condition A\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(t, EEGa[0])                     # Plot condition A, trial 1 data vs t.\n",
    "plt.xlabel('Time [s]')                   # Label the x-axis as time.\n",
    "plt.ylabel('Voltage [µV]')               # Label the y-axis as voltage.\n",
    "plt.title('EEG data from condition A, Trial 1')  # Add a title\n",
    "\n",
    "# Add a vertical line to indicate the stimulus time\n",
    "plt.axvline(x=0.25, color='red', linestyle='--', linewidth=2, label='Stimulus onset')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Let's also examine the first trial from condition B for comparison\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(t, EEGa[0], label='Condition A (High pitch)', alpha=0.7)\n",
    "plt.plot(t, EEGb[0], 'r', label='Condition B (Low pitch)', alpha=0.7)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Voltage [µV]')\n",
    "plt.title('Single trial comparison: Condition A vs Condition B')\n",
    "plt.axvline(x=0.25, color='black', linestyle='--', linewidth=2, label='Stimulus onset')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how noisy the single trial data is!\")\n",
    "print(\"This is why we need to average across many trials to see the ERP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aad137",
   "metadata": {},
   "source": [
    "## 4a. Computing Event-Related Potentials (ERPs)\n",
    "\n",
    "In Section 4 we framed the problem and reviewed why averaging reveals stimulus-locked brain responses. You've now seen the raw single-trial variability — so this step is simply turning those many noisy repetitions into a clearer signal.\n",
    "\n",
    "### What We Do Here\n",
    "1. Average EEG signals across trials (one mean waveform per condition)\n",
    "2. Align interpretation to the stimulus onset\n",
    "3. Quantify uncertainty with a 95% confidence interval (via the Central Limit Theorem approximation: mean ± 2·SEM)\n",
    "4. Prepare for statistical comparison between conditions\n",
    "\n",
    "> ***Background**: The Central Limit Theorem states that the mean of a sufficiently large number of independent random variables, each with finite mean and variance, will be approximately normally distributed\n",
    "\n",
    "> ***Question**: What assumptions do we make by using the central limit theorem?\n",
    "\n",
    "> **Answer**: We assume that 1) the data is independent across trials, and 2) that the data's variance and mean is always finite (does not go to plus or minus infinity)\n",
    "\n",
    "> ***Question**: Are these reasonable assumptions to make?\n",
    "\n",
    "> **Answer**: Assumption 1: Yes, but may not be for some other experiments where one trial's data may be dependent on (aka influenced by) the previous trial (for example, an experiement where a participant may be learning or memorizing information from previous trials) Assumption 2: Yes because we can assume that brains EEG recordings don't go to plus or minus infinity, and so the variance and mean can be assumed to remain finite.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ERPs by averaging across trials\n",
    "mnA = np.mean(EEGa, axis=0)  # ERP for condition A\n",
    "mnB = np.mean(EEGb, axis=0)  # ERP for condition B\n",
    "\n",
    "# Compute standard deviation\n",
    "sdA = np.std(EEGa, axis=0)   # Std across trials (A)\n",
    "sdB = np.std(EEGb, axis=0)   # Std across trials (B)\n",
    "\n",
    "# Standard error of the mean\n",
    "semnA = sdA / np.sqrt(ntrials)\n",
    "semnB = sdB / np.sqrt(ntrials)\n",
    "\n",
    "# 95% CI bounds (using CLT: ±2*SEM)\n",
    "upperA = mnA + 2 * semnA\n",
    "lowerA = mnA - 2 * semnA\n",
    "upperB = mnB + 2 * semnB\n",
    "lowerB = mnB - 2 * semnB\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Condition A (mean->upper and mean->lower)\n",
    "plt.fill_between(t, mnA, upperA, where=upperA>=mnA, color='blue', alpha=0.15, linewidth=0)\n",
    "plt.fill_between(t, mnA, lowerA, where=lowerA<=mnA, color='blue', alpha=0.08, linewidth=0)\n",
    "\n",
    "# Condition B (mean->upper and mean->lower)\n",
    "plt.fill_between(t, mnB, upperB, where=upperB>=mnB, color='red', alpha=0.15, linewidth=0)\n",
    "plt.fill_between(t, mnB, lowerB, where=lowerB<=mnB, color='red', alpha=0.08, linewidth=0)\n",
    "\n",
    "# Mean ERPs\n",
    "plt.plot(t, mnA, 'b-', linewidth=2.5, label='Condition A (High pitch)')\n",
    "plt.plot(t, mnB, 'r-', linewidth=2.5, label='Condition B (Low pitch)')\n",
    "\n",
    "\n",
    "# Stimulus timing\n",
    "plt.axvline(x=0.25, color='black', linestyle='--', linewidth=2, label='Stimulus onset')\n",
    "plt.axhline(0, t[0], t[-1], color='gray', linewidth=0.8, alpha=0.7)\n",
    "\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Voltage [µV]')\n",
    "plt.title('Event-Related Potentials with Mean-to-CI Shading (95% CI)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some basic statistics\n",
    "print(\"ERP Analysis Results:\")\n",
    "print(f\"Number of trials per condition: {ntrials}\")\n",
    "print(\"\\nCondition A ERP:\")\n",
    "print(f\"  Peak amplitude: {np.max(np.abs(mnA)):.3f} µV\")\n",
    "print(f\"  Time of peak: {t[np.argmax(np.abs(mnA))]:.3f} s\")\n",
    "print(\"\\nCondition B ERP:\")\n",
    "print(f\"  Peak amplitude: {np.max(np.abs(mnB)):.3f} µV\")\n",
    "print(f\"  Time of peak: {t[np.argmax(np.abs(mnB))]:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d1919",
   "metadata": {},
   "source": [
    "## 4b. Comparing ERPs Between Conditions (without Bootstrap)\n",
    "\n",
    "Now that we have computed ERPs for both conditions, let's examine their differences more carefully. We'll compute the difference wave and assess whether the conditions significantly differ.\n",
    "\n",
    "If zero isn't included within the range of the confidence intervals, we can say that the conditions significantly differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference between mean signals across ERP conditions\n",
    "mnA = np.mean(EEGa,0)          # Determine ERP for condition A\n",
    "mnB = np.mean(EEGb,0)          # Determine ERP for condition B\n",
    "sdmeanA = np.std(EEGa,0) / np.sqrt(ntrials) # Compute standard deviation of the mean for condition A\n",
    "sdmeanB = np.std(EEGb,0) / np.sqrt(ntrials) # Compute standard deviation of the meanfor condition B\n",
    "mnD = mnA - mnB             # Compute the mean difference between ERPs\n",
    "stat = np.max(np.abs(mnD))        # Compute the statistic (max absolute difference)\n",
    "print('stat = {:.4f}'.format(stat))\n",
    "\n",
    "# Standard deviation of the mean difference\n",
    "sdmeanD = np.sqrt(sdmeanA**2 + sdmeanB**2) \n",
    "\n",
    "# Plot the difference wave with confidence intervals\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot difference wave\n",
    "plt.plot(t, mnD, 'k-', linewidth=3, label='Difference (A - B)')\n",
    "plt.plot(t, mnD + 2 * sdmeanD, 'k:', linewidth=1, alpha=0.7, label='95% CI')\n",
    "plt.plot(t, mnD - 2 * sdmeanD, 'k:', linewidth=1, alpha=0.7)\n",
    "\n",
    "# Add reference lines\n",
    "plt.axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "plt.axvline(x=0.25, color='red', linestyle='--', linewidth=2, label='Stimulus onset')\n",
    "\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Voltage Difference [µV]')\n",
    "plt.title('Difference Wave: Condition A - Condition B')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a81238",
   "metadata": {},
   "source": [
    "## 5a. Doing it Again Differently: Bootstrap Confidence Intervals for ERPs\n",
    "\n",
    "While the Central Limit Theorem gives us a way to compute confidence intervals, we can also use bootstrapping; a powerful computational technique that doesn't rely on assumptions about the underlying distribution.\n",
    "\n",
    "**Bootstrap procedure:**\n",
    "The bootstrap procedure allows us to estimate the distribution of many different statistics, offering more versatility. This allows us to estimate the confidence intervals without relying on the assumption that the underlying distribution is approximately normal.\n",
    "\n",
    "**How we'll implement this:**\n",
    "1. Sample with replacement 1,000 trials of the EEG data from condition A, then B.\n",
    "2. Compute the ERP for each resampled dataset (again, just averaging the trials)\n",
    "3. Repeat many times (3,000 times) to create a distribution of possible ERPs\n",
    "4. Use percentiles of this distribution to construct confidence intervals\n",
    "\n",
    "Let's implement bootstrap confidence intervals for our ERPs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d25f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap function for computing bootstrap confidence intervals for both ERPs (overlaid plot)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bootstrapERPdata(EEGdata, size=None):\n",
    "    \"\"\"Return one bootstrap ERP (mean of resampled trials).\"\"\"\n",
    "    ntrials_local = len(EEGdata)\n",
    "    if size is None:\n",
    "        size = ntrials_local\n",
    "    idx = np.random.randint(ntrials_local, size=size)\n",
    "    return EEGdata[idx].mean(0)\n",
    "\n",
    "n_bootstrap = 3000\n",
    "print(f\"Bootstrapping {n_bootstrap} ERPs per condition for 95% CIs...\")\n",
    "\n",
    "# Generate bootstrap samples\n",
    "bootstrapERPA = np.array([bootstrapERPdata(EEGa) for _ in range(n_bootstrap)])\n",
    "bootstrapERPB = np.array([bootstrapERPdata(EEGb) for _ in range(n_bootstrap)])\n",
    "\n",
    "# Sort each column for percentile lookup\n",
    "bootstrapERPA.sort(axis=0)\n",
    "bootstrapERPB.sort(axis=0)\n",
    "N = n_bootstrap\n",
    "\n",
    "# Percentile indices (simple integer lookup)\n",
    "ciLA = bootstrapERPA[int(0.025 * N)]\n",
    "ciUA = bootstrapERPA[int(0.975 * N)]\n",
    "ciLB = bootstrapERPB[int(0.025 * N)]\n",
    "ciUB = bootstrapERPB[int(0.975 * N)]\n",
    "\n",
    "# Mean ERPs\n",
    "mnA = np.mean(EEGa, 0)\n",
    "mnB = np.mean(EEGb, 0)\n",
    "\n",
    "# Expose for later summary cell (keep naming convention)\n",
    "ci_lower_A, ci_upper_A = ciLA, ciUA\n",
    "ci_lower_B, ci_upper_B = ciLB, ciUB\n",
    "\n",
    "# Single overlaid plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Condition A shading & mean\n",
    "plt.fill_between(t, ci_lower_A, ci_upper_A, color='teal', alpha=0.70, linewidth=0, label='A 95% CI (bootstrap)')\n",
    "plt.plot(t, mnA, 'b-', lw=2.5, label='Condition A ERP')\n",
    "\n",
    "# Condition B shading & mean\n",
    "plt.fill_between(t, ci_lower_B, ci_upper_B, color='pink', alpha=0.70, linewidth=0, label='B 95% CI (bootstrap)')\n",
    "plt.plot(t, mnB, 'r-', lw=2.5, label='Condition B ERP')\n",
    "\n",
    "# Reference lines\n",
    "plt.axvline(0.25, color='black', ls='--', lw=2, label='Stimulus onset')\n",
    "plt.axhline(0, color='gray', lw=0.8, alpha=0.6)\n",
    "\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Voltage [µV]')\n",
    "plt.title('Overlaid ERPs with Bootstrap 95% Confidence Intervals')\n",
    "plt.legend(frameon=False)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d25f9",
   "metadata": {},
   "source": [
    "## 5b. Comparing the ERPs between both conditions: Bootstrap test\n",
    "\n",
    "Is this difference significant, or is it due to randomness?\n",
    "\n",
    "We'll use the bootstrap procedure, similar to how we used it to construct confidence intervals.\n",
    "\n",
    "This time, we'll merge the two EEG datasets from both conditions (for a total of 2000 trials) and resample with replacement.\n",
    "\n",
    "> Question: Doesn't that defeat the purpose of having separate conditions?\n",
    "\n",
    "> Answer: While it may seem counter intuitive to mix up trials from both conditions, if the data from both conditions don't significantly differ, then our test statistic wouldn't significantly differ. This allows us to confirm or deny if these two conditions differ.\n",
    "\n",
    "We use the null hypothesis h0: there is no significant difference between the two conditions\n",
    "\n",
    "If the null hypothesis holds, then we would see that the test statistic we calculated above would fall well within the distribution of test statistics from the bootstrap resampling \n",
    "\n",
    "**Bootstrap test procedure:**\n",
    "1. Merge the 1,000 trials each of EEG data from conditions A and B to form a combined distribution of 2,000 trials.\n",
    "2. Randomly sample with replacement 1,000 trials of EEG data from the combined distribution, and compute the resampled ERP.\n",
    "3. Repeat step 2 and compute a second resampled ERP.\n",
    "4. Compute the statistic, the maximum absolute value of the difference between the two resampled ERPs.\n",
    "5. Repeat steps 2-4, 3,000 times to create a distribution of statistic values.\n",
    "6. Compare the observed statistic (the one we initially got during 4b) to this distribution of statistic values. If the observed statistic is greater than 95% of the bootstrapped values, then reject the null hypothesis that the two conditions are the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aeb148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap hypothesis test (6-step procedure) using provided bootstrapERP helper\n",
    "from numpy.random import randint\n",
    "\n",
    "# Observed statistic (already computed earlier in cell 4b as stat = np.max(np.abs(mnD)) ... mnD = mean difference = mnA - mnB)\n",
    "observed_stat = np.max(np.abs(mnD))\n",
    "print(f\"Observed statistic (max |A-B|): {observed_stat:.5f}\")\n",
    "\n",
    "# Merge trials from both conditions under H0\n",
    "eeg_combined = np.vstack((EEGa, EEGb))\n",
    "combined_n = eeg_combined.shape[0]\n",
    "print(f\"Combined trials: {combined_n}\")\n",
    "\n",
    "n_bootstrap_test = 3000\n",
    "sample_size = ntrials\n",
    "null_stats_max_absolute_difference = np.empty(n_bootstrap_test)\n",
    "\n",
    "for b in range(n_bootstrap_test):\n",
    "    # Draw two independent bootstrapped ERPs from pooled data\n",
    "    erp1 = bootstrapERPdata(eeg_combined, size=sample_size)\n",
    "    erp2 = bootstrapERPdata(eeg_combined, size=sample_size)\n",
    "    # add the max absolute difference observed in this bootstrap iteration to null_stats...\n",
    "    null_stats_max_absolute_difference[b] = np.max(np.abs(erp1 - erp2))\n",
    "    if b % 500 == 0:\n",
    "        print(f\"  Bootstrap test iteration {b}/{n_bootstrap_test}\")\n",
    "\n",
    "# calculate p-value: average of null stats >= observed stat / proportion of null stats exceeding observed stat\n",
    "p_value = np.mean(null_stats_max_absolute_difference >= observed_stat)\n",
    "threshold_95 = np.percentile(null_stats_max_absolute_difference, 95)\n",
    "\n",
    "print(\"\\nBootstrap Hypothesis Test Results (Resample-with-Replacement Null)\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(f\"Observed statistic:        {observed_stat:.5f}\")\n",
    "print(f\"95th percentile threshold: {threshold_95:.5f}\")\n",
    "print(f\"P-value (>= observed):     {p_value:.6f}\")\n",
    "if observed_stat > threshold_95:\n",
    "    print(\"Decision: REJECT H0 (difference exceeds 95% of null statistics)\")\n",
    "else:\n",
    "    print(\"Decision: FAIL TO REJECT H0 (difference within null expectations)\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(null_stats_max_absolute_difference, bins=50, color='lightsteelblue', alpha=0.8, label='Null stats (bootstrap)')\n",
    "plt.axvline(observed_stat, color='red', linestyle='--', linewidth=2, label=f'Observed = {observed_stat:.4f}')\n",
    "plt.axvline(threshold_95, color='black', linestyle='-', linewidth=2, label=f'95th pct = {threshold_95:.4f}')\n",
    "plt.xlabel('Max |ERP1 - ERP2| (null resamples)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Bootstrap Null Distribution of Max Absolute ERP Difference')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285dd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary figure showing all our ERP analyses\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "# Top panel: Individual trials and ERPs\n",
    "axes[0].plot(t, EEGa[0], 'b-', alpha=0.3, label='Single trial A')\n",
    "axes[0].plot(t, EEGb[0], 'r-', alpha=0.3, label='Single trial B')\n",
    "axes[0].plot(t, mnA, 'b-', linewidth=3, label='ERP A (avg of 1000 trials)')\n",
    "axes[0].plot(t, mnB, 'r-', linewidth=3, label='ERP B (avg of 1000 trials)')\n",
    "axes[0].axvline(x=0.25, color='black', linestyle='--', alpha=0.7, label='Stimulus')\n",
    "axes[0].set_ylabel('Voltage [µV]')\n",
    "axes[0].set_title('Single Trials vs ERPs')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Middle panel: ERPs with confidence intervals\n",
    "axes[1].plot(t, mnA, 'b-', linewidth=3, label='Condition A')\n",
    "axes[1].fill_between(t, ci_lower_A, ci_upper_A, color='blue', alpha=0.2)\n",
    "axes[1].plot(t, mnB, 'r-', linewidth=3, label='Condition B') \n",
    "axes[1].fill_between(t, ci_lower_B, ci_upper_B, color='red', alpha=0.2)\n",
    "axes[1].axvline(x=0.25, color='black', linestyle='--', alpha=0.7, label='Stimulus')\n",
    "axes[1].set_ylabel('Voltage [µV]')\n",
    "axes[1].set_title('ERPs with Bootstrap 95% Confidence Intervals')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Bottom panel: Difference wave\n",
    "axes[2].plot(t, mnD, 'k-', linewidth=3, label='Difference (A - B)')\n",
    "axes[2].plot(t, mnD + 2 * semnD, 'k:', alpha=0.7, label='95% CI (CLT)')\n",
    "axes[2].plot(t, mnD - 2 * semnD, 'k:', alpha=0.7)\n",
    "axes[2].axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "axes[2].axvline(x=0.25, color='black', linestyle='--', alpha=0.7, label='Stimulus')\n",
    "axes[2].set_xlabel('Time [s]')\n",
    "axes[2].set_ylabel('Voltage Difference [µV]')\n",
    "axes[2].set_title('Difference Wave with Statistical Significance')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ERP Analysis Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Data: {ntrials} trials per condition, {nsamples} time points\")\n",
    "print(f\"Sampling rate: {1/(t[1]-t[0]):.0f} Hz\")\n",
    "print(f\"Trial duration: {t[-1]:.3f} seconds\")\n",
    "print(f\"Stimulus onset: 0.250 seconds\")\n",
    "print()\n",
    "print(\"Statistical Results:\")\n",
    "print(f\"Bootstrap permutation test p-value: {p_value:.6f}\")\n",
    "print(f\"Significant difference: {'YES' if p_value < 0.05 else 'NO'} (α = 0.05)\")\n",
    "print()\n",
    "print(\"Peak Analysis:\")\n",
    "print(f\"Condition A peak: {np.max(np.abs(mnA)):.3f} µV at {t[np.argmax(np.abs(mnA))]:.3f} s\")\n",
    "print(f\"Condition B peak: {np.max(np.abs(mnB)):.3f} µV at {t[np.argmax(np.abs(mnB))]:.3f} s\")\n",
    "print(f\"Max difference: {np.max(np.abs(mnD)):.3f} µV at {t[np.argmax(np.abs(mnD))]:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d4887",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we conducted a complete analysis of EEG Event-Related Potentials (ERPs), demonstrating how Python can be used for real neuroscience research. Here's what we accomplished:\n",
    "\n",
    "### Data Analysis Pipeline\n",
    "1. **Data Loading**: Imported EEG data from MATLAB format using `scipy.io.loadmat`\n",
    "2. **Visual Inspection**: Examined single trials to understand the noisy nature of raw EEG\n",
    "3. **ERP Computation**: Averaged across trials to reveal stimulus-locked neural responses\n",
    "4. **Statistical Analysis**: Applied both Central Limit Theorem and bootstrap methods for confidence intervals\n",
    "5. **Hypothesis Testing**: Used bootstrap permutation tests to compare conditions statistically\n",
    "\n",
    "### Key Python Concepts Applied\n",
    "- **NumPy arrays** for efficient numerical computation\n",
    "- **Matplotlib** for comprehensive data visualization  \n",
    "- **SciPy** for loading scientific data formats\n",
    "- **Functions** to organize reusable analysis code\n",
    "- **Control flow** for iterative bootstrap procedures\n",
    "- **Statistical thinking** through confidence intervals and hypothesis testing\n",
    "\n",
    "### Scientific Results\n",
    "We analyzed EEG responses to high-pitch vs low-pitch tones and found:\n",
    "- Clear event-related potentials in both conditions\n",
    "- Statistical methods revealed significant differences between conditions\n",
    "- Bootstrap procedures confirmed our findings without relying on distributional assumptions\n",
    "\n",
    "### Methodological Insights\n",
    "- **Single trials are noisy** - averaging across trials is essential to reveal ERPs\n",
    "- **Multiple statistical approaches** - CLT and bootstrap methods can complement each other\n",
    "- **Visualization is critical** - plots help us understand both data and statistical results\n",
    "- **Computational statistics** - bootstrap methods provide powerful, assumption-free analysis tools\n",
    "\n",
    "## Next Steps in ERP Analysis\n",
    "- **Topographic analysis**: Examine spatial patterns across multiple electrodes\n",
    "- **Time-frequency analysis**: Investigate oscillatory components of the response\n",
    "- **Component analysis**: Use techniques like ICA to separate neural sources\n",
    "- **Statistical power**: Determine optimal sample sizes for future experiments\n",
    "\n",
    "## Donate\n",
    "If you enjoy these tutorials and would like to support continued development of educational neuroscience content, consider supporting the original Case Studies in Neural Data Analysis project at: https://www.paypal.com/donate/?hosted_button_id=DL8P5ZGS9962U\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: The best way to learn is by doing. Take these ERP analysis techniques and apply them to your own research questions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
